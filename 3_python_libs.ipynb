{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NumPy\n",
        "\n",
        "**NumPy** (**Num**erical **Py**thon)is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n",
        "\n",
        "Its **high level syntax** makes it **accessible** and productive for programmers from any background or experience level, while its core is **well-optimized C code** to combine the **flexibility** of Python with the **speed** of compiled code."
      ],
      "metadata": {
        "id": "66fMwjQUPjlg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Arrays\n",
        "An **array** is the central data structure of the NumPy library. An array is a grid of values and it contains information about \n",
        "- the raw data\n",
        "- how to locate an element\n",
        "- how to interpret an element. \n",
        "\n",
        "It has a grid of elements that can be indexed in various ways. The elements are all of the same type, referred to as the array **dtype**.\n",
        "\n",
        "The **rank** of the array is the number of dimensions. The **shape** of the array is a tuple of integers giving the size of the array along each dimension. In Numpy, dimensions are called **axes**.\n",
        "\n",
        "While a Python list can contain different data types within a single list, all of the elements in a NumPy array should be **homogeneous**. The mathematical operations that are meant to be performed on arrays would be extremely inefficient otherwise. NumPy arrays are **faster** and more **compact** than Python lists. NumPy uses much **less memory** to store data.\n",
        "\n",
        "There are different ways to initialize a _numpy array_:\n",
        "\n",
        "- With regular Python arrays"
      ],
      "metadata": {
        "id": "da5OArvpP2TV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a1d = np.array([1, 2, 3])\n",
        "a2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8 , 9]])\n",
        "a3d = np.array([[[1, 2, 3], [4, 5, 6], [7, 8 , 9]], [[1, 2, 3], [4, 5, 6], [7, 8 , 9]], [[1, 2, 3], [4, 5, 6], [7, 8 , 9]]])\n",
        "print(a1d, \"\\n\")\n",
        "print(a2d, \"\\n\")\n",
        "print(a3d)"
      ],
      "metadata": {
        "id": "-lEKLEUsRlFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- With numpy functions to repeat data"
      ],
      "metadata": {
        "id": "AjR5Y6cN9wne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "print([0, 0])\n",
        "print(np.zeros(5))\n",
        "print(np.ones(5))\n",
        "print(np.arange(7, 49, 7)) # 49 not included"
      ],
      "metadata": {
        "id": "Ft8449xYag6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- With numpy functions to generate distributions: linear, geometric, logaritmic..."
      ],
      "metadata": {
        "id": "p2GX8tBl95zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "print(np.linspace(1, 100, 10))\n",
        "print(np.geomspace(1, 100, 10))\n",
        "print(np.logspace(1, 100, 10))\n",
        "print(np.logspace(0, 2, 10))\n"
      ],
      "metadata": {
        "id": "lL0_pa1jbhfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Basic array operations\n",
        "Numpy arrays have attributes with information about its shape, size and dimmensions."
      ],
      "metadata": {
        "id": "9P0pyueLdnVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a1d = np.array([1, 2, 3])\n",
        "a2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "a2d2 = np.array([[1], [4, 5, 6], [7, 8]])\n",
        "a2d3 = np.array([[1, None, None], [4, 5, 6], [7, 8, None]])\n",
        "\n",
        "print(a1d.size, a1d.ndim, a1d.shape)\n",
        "print(a2d.size, a2d.ndim, a2d.shape)\n",
        "print(a2d2.size, a2d2.ndim, a2d2.shape)\n",
        "print(a2d3.size, a2d3.ndim, a2d3.shape)\n",
        "# remove a2d2 to avoid warning"
      ],
      "metadata": {
        "id": "jqLguspDdr6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also join arrays, break them in pieces or change their shape."
      ],
      "metadata": {
        "id": "kTSD1Bxv0L_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "arr = np.array([1, 2, 3, 5, 2, 4, 3, 2, 5, 6, 1, 2, None, 5])\n",
        "print(arr[4:7], arr[7:], arr[:2])\n",
        "print(np.split(arr, 2))\n",
        "\n",
        "print()\n",
        "\n",
        "arra = np.array([1, 2, 3, 3, 2, 5])\n",
        "arrb = np.array([8, 5, 2, 4, 6, 1, 2, 5])\n",
        "arr2 = np.concatenate((arra, arrb))\n",
        "print(arr2)\n",
        "print(np.flip(arr2))\n",
        "print(np.sort(arr2))\n",
        "print(np.unique(arr2))\n",
        "print(arr2.reshape(2, 7)) # try different numbers"
      ],
      "metadata": {
        "id": "bCFFKp02uT96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Basic numeric operations: broadcasting\n",
        "**Broadcasting** is the term used to describe the implicit element-by-element behavior of operations; generally speaking, in NumPy all operations, not just arithmetic operations, but logical, bit-wise, functional, etc., behave in this implicit element-by-element fashion.\n",
        "\n",
        "**Looping occurs in C instead of Python!**\n",
        "\n",
        "In regular Python..."
      ],
      "metadata": {
        "id": "LfrJZczrLuar"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYI32ecsPcB9"
      },
      "outputs": [],
      "source": [
        "a = [1, 2, 3]\n",
        "b = [15, 25, 30]\n",
        "c = []\n",
        "for i in range(len(a)):\n",
        "  c.append(a[i] * b[i])\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With _Numpy_"
      ],
      "metadata": {
        "id": "2vb8J_YjEofx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jVyrD_qhqap"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([15, 25, 30])\n",
        "c = 2.35\n",
        "print(a * b)\n",
        "print(a * c)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More examples."
      ],
      "metadata": {
        "id": "p10agMYtExb3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1txJQ9hUKqLD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([5, 15, 10])\n",
        "c = 3\n",
        "print(np.power(a, b))\n",
        "print(np.power(a, c))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZAmYgquXhqq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "print(np.sqrt(a))\n",
        "print(np.square(a))\n",
        "print(np.exp(a))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "arr = np.array([-0.8, 4.1, -9.7, -8, 5])\n",
        "print(np.round(arr))\n",
        "print(np.ceil(arr))\n",
        "print(np.floor(arr))"
      ],
      "metadata": {
        "id": "-lPRK4yvOlir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grouping\n",
        "We can find some statistical data from a group: maximum, minimum, mean..."
      ],
      "metadata": {
        "id": "hUsDLQRvL7eH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "arr = np.array([-0.8, 4.1, -9.7, -8, 5])\n",
        "print('Sum:', arr.sum())\n",
        "print('Max:', arr.max())\n",
        "print('Min:', arr.min())\n",
        "print('Mean:', arr.mean())\n",
        "print('Standard deviation:', arr.std())"
      ],
      "metadata": {
        "id": "8uSAHC_xSf_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Selecting\n",
        "We can also select data that meets certain conditions."
      ],
      "metadata": {
        "id": "W2j0jyDhYPFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "arr = np.array([1, 2, 3, 5, 2, 4, 3, 2, 5, 6, 1, 2, 5])\n",
        "print(np.unique(arr))\n",
        "print(np.where(arr < 5))\n",
        "print(arr[np.where(arr < 5)])"
      ],
      "metadata": {
        "id": "wvNl4M9CYSiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random\n",
        "There are several _numpy_ functions to generate random data."
      ],
      "metadata": {
        "id": "EOGqnhbQM927"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "print(np.random.rand(10))\n",
        "print()\n",
        "print(np.random.rand(3, 6))\n",
        "print()\n",
        "print(np.random.randn(10))\n",
        "print()\n",
        "print(np.random.randint(low = 1, high = 25, size = (5, 5)))\n",
        "print()\n",
        "\n",
        "choices = [1, 10, 100, 1000]\n",
        "chances = [0.5, 0.1, 0.1, 0.3]\n",
        "print(np.random.choice(choices, 10, p = chances))\n"
      ],
      "metadata": {
        "id": "tZCwCuTgNAd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Basic statistics\n",
        "Statistical data is really easy to btain with _numpy_."
      ],
      "metadata": {
        "id": "L-VwqrimSTXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "arr = np.array([1, 2, 3, 5, 2, 4, 3, 2, 5, 6, 1, 2, 5])\n",
        "print(arr.mean())\n",
        "print(arr.std())\n",
        "print(np.percentile(arr, 80))\n",
        "print()\n",
        "choices = [1, 10, 100, 1000]\n",
        "chances = [0.5, 0.1, 0.1, 0.3]\n",
        "print(np.average(choices, weights = chances))"
      ],
      "metadata": {
        "id": "GcGw97yvJEw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Matrixes\n",
        "We can also create and operate matrixes with _numpy_."
      ],
      "metadata": {
        "id": "mQy0rRVaiwPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "m = np.array(matrix)\n",
        "print(m, \"\\n\")\n",
        "print(m + m, \"\\n\")\n",
        "print(m * m, \"\\n\")\n",
        "print(np.diag(m), \"\\n\")\n",
        "print(np.flipud(m), \"\\n\")\n",
        "print(np.fliplr(m), \"\\n\")\n",
        "print(np.transpose(m), \"\\n\")\n",
        "print(m * np.transpose(m))\n"
      ],
      "metadata": {
        "id": "k-_w57V5i1cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MatPlotLib\n",
        "_Matplotlib_ is a comprehensive library for creating static, animated, and interactive visualizations in Python.\n",
        "\n",
        "You can find a full reference at https://matplotlib.org/.\n",
        "\n",
        "Let's see a few cool examples.\n",
        "\n"
      ],
      "metadata": {
        "id": "RNDPgoBbrNRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Correlogram\n",
        "_Seaborn_ library is a widely popular data visualization library that is built on top of the Matplotlib and can perform exploratory analysis. You can find a full reference at https://seaborn.pydata.org/.\n",
        "\n",
        "A _correlogram_ is used to visually see the **correlation** metric between all possible pairs of numeric variables in a given dataframe."
      ],
      "metadata": {
        "id": "JFuRMM2lhWUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv(\"https://github.com/selva86/datasets/raw/master/mtcars.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "QlDX1tKHhmxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "id": "yn7HQzORbzaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (12, 10), dpi = 80)\n",
        "sns.heatmap(df.corr(), xticklabels = df.corr().columns, yticklabels = df.corr().columns, cmap = 'RdYlGn', center = 0, annot = True)\n",
        "plt.title('Correlogram of mtcars', fontsize = 22)\n",
        "plt.xticks(fontsize = 12)\n",
        "plt.yticks(fontsize = 12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BSvdWFXhb4ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Slope Chart\n",
        "Slope chart is most suitable for comparing _before_ and _after_ positions of a given item. We can test a lot of code here!"
      ],
      "metadata": {
        "id": "Y-peAcKVjRy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.lines as mlines\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/selva86/datasets/master/gdppercap.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "la4b4x3kjpge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def newline(p1, p2, color = 'black'):\n",
        "    ax = plt.gca()\n",
        "    l = mlines.Line2D([p1[0], p2[0]], [p1[1], p2[1]], color = 'red' if p1[1] > p2[1] else 'green', marker = 'o', markersize = 6)\n",
        "    ax.add_line(l)\n",
        "    return l\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize = (14, 14), dpi = 80)\n",
        "\n",
        "# Vertical Lines\n",
        "ax.vlines(x =1, ymin = 500, ymax = 13000, color = 'black', alpha = 0.7, linewidth = 1, linestyles = 'dotted')\n",
        "ax.vlines(x =3, ymin = 500, ymax = 13000, color = 'black', alpha = 0.7, linewidth = 1, linestyles = 'dotted')\n",
        "\n",
        "# Points\n",
        "ax.scatter(y = df['1952'], x = np.repeat(1, df.shape[0]), s = 10, color = 'black', alpha = 0.7)\n",
        "ax.scatter(y = df['1957'], x = np.repeat(3, df.shape[0]), s = 10, color = 'black', alpha = 0.7)\n",
        "\n",
        "# Line Segmentsand Annotation\n",
        "for p1, p2, c in zip(df['1952'], df['1957'], df['continent']):\n",
        "    newline([1, p1], [3, p2])\n",
        "    ax.text(1 - 0.05, p1, c + ', ' + str(round(p1)), horizontalalignment = 'right', verticalalignment ='center', fontdict = {'size': 14})\n",
        "    ax.text(3 + 0.05, p2, c + ', ' + str(round(p2)), horizontalalignment = 'left', verticalalignment = 'center', fontdict = {'size': 14})\n",
        "\n",
        "# 'Before' and 'After' Annotations\n",
        "ax.text(1-0.05, 13000, 'Before', horizontalalignment = 'right', verticalalignment = 'center', fontdict = {'size': 18, 'weight': 700})\n",
        "ax.text(3+0.05, 13000, 'After', horizontalalignment = 'left', verticalalignment = 'center', fontdict = {'size': 18, 'weight': 700})\n",
        "\n",
        "# Decoration\n",
        "ax.set_title(\"Slopechart: Comparing GDP Per Capita between 1952 vs 1957\", fontdict = {'size': 22})\n",
        "ax.set(xlim = (0, 4), ylim = (0, 14000), ylabel = 'Mean GDP Per Capita')\n",
        "ax.set_xticks([1, 3])\n",
        "ax.set_xticklabels([\"1952\", \"1957\"])\n",
        "plt.yticks(np.arange(500, 13000, 2000), fontsize = 12)\n",
        "\n",
        "# Lighten borders\n",
        "plt.gca().spines[\"top\"].set_alpha(.50)\n",
        "plt.gca().spines[\"bottom\"].set_alpha(.50)\n",
        "plt.gca().spines[\"right\"].set_alpha(.50)\n",
        "plt.gca().spines[\"left\"].set_alpha(.50)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5hNlALQVcLhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Joy Plot\n",
        "_JoyPy_ is a one-function Python package based on matplotlib + pandas with a single purpose: drawing ridgeline plots (joyplots). You can find it here https://github.com/leotac/joypy.\n",
        "\n",
        "Joyplots are stacked, partially overlapping density plots. They are a useful to plot data to visually compare distributions, especially those that change across one dimension (e.g., over time)."
      ],
      "metadata": {
        "id": "_4_T7--k9cPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joypy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import joypy\n",
        "\n",
        "df = pd.read_csv(\"https://github.com/selva86/datasets/raw/master/mpg_ggplot2.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "866HHqbw-N3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw Plot\n",
        "plt.figure(figsize = (10, 6), dpi = 80)\n",
        "fig, axes = joypy.joyplot(df, column = ['hwy', 'cty'], by = \"class\", ylim = 'own', figsize = (10, 6))\n",
        "\n",
        "# Decoration\n",
        "plt.title('Joy Plot of City and Highway Mileage by Class', fontsize = 22)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HnXKOjsbcgj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#StatsModels\n",
        "*statsmodels* is a Python module that provides classes and functions for the estimation of many different **statistical models**, as well as for conducting statistical tests, and statistical data exploration. It supports ``numpy`` arrays as well as ``pandas`` dataframes.\n",
        "\n",
        "You can find the complete list of *statsmodel* supported models at https://www.statsmodels.org/stable/api.html.\n"
      ],
      "metadata": {
        "id": "3IYgvmhXY7Fd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ARIMA\n",
        "**ARIMA** is a statistical analysis model that uses time series data to either better understand the data set or to predict future trends. The name stands for **A**uto**R**egressive **I**ntegrated **M**oving **A**verage. You can find more information about ARIMA at https://www.investopedia.com/terms/a/autoregressive-integrated-moving-average-arima.asp or at https://towardsdatascience.com/machine-learning-part-19-time-series-and-autoregressive-integrated-moving-average-model-arima-c1005347b0d7."
      ],
      "metadata": {
        "id": "dQhpe7dS8V2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data\n",
        "Let's see how does our timeseries data look like."
      ],
      "metadata": {
        "id": "vniC9mFCeywY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "df = pd.read_csv('screenviews_by_date_country_devcat.csv', parse_dates = ['ga_date'], index_col = ['ga_date'])\n",
        "aggr_df = df.groupby(\"ga_date\").agg({\"ga_screenviews\": np.sum }) \n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Screenviews')\n",
        "plt.plot(aggr_df)"
      ],
      "metadata": {
        "id": "XuhJbnm2i6Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model\n",
        "Let's now create a model and see how it looks."
      ],
      "metadata": {
        "id": "fiesDUpie3a8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "model = ARIMA(aggr_df, order = (3, 1, 0))\n",
        "results = model.fit()\n",
        "print(results.summary())\n",
        "results.plot_diagnostics()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LouLu1yxbnNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Forecast\n",
        "Let's check our past data and what the model predicts."
      ],
      "metadata": {
        "id": "okcc7gAkyudK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(aggr_df)\n",
        "plt.plot(results.fittedvalues, color = 'red')\n",
        "plt.plot(results.forecast(12), color = 'green')\n",
        "plt.show()\n",
        "print()\n",
        "print(results.forecast(2))"
      ],
      "metadata": {
        "id": "hdtZzwtty9uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SciPy\n",
        "**SciPy** is a collection of mathematical algorithms and convenience functions built on the **NumPy** extension of Python. You can find a complete reference in https://scipy.org/.\n",
        "\n",
        "This is the list of packages avaiable in _SciPy_:\n",
        "- cluster: Clustering algorithms\n",
        "- constants: Physical and mathematical constants\n",
        "- fftpack: Fast Fourier Transform routines\n",
        "- integrate: Integration and ordinary differential equation solvers\n",
        "- interpolate: Interpolation and smoothing splines\n",
        "- io: Input and Output\n",
        "- linalg: Linear algebra\n",
        "- ndimage: N-dimensional image processing\n",
        "- odr: Orthogonal distance regression\n",
        "- optimize: Optimization and root-finding routines\n",
        "- signal: Signal processing\n",
        "- sparse: Sparse matrices and associated routines\n",
        "- spatial: Spatial data structures and algorithms\n",
        "- special: Special functions\n",
        "- stats: Statistical distributions and functions\n",
        "\n",
        "As you can see, you need previous mathematical knowledge to be able to use _SciPy_ library. Let's see some examples:"
      ],
      "metadata": {
        "id": "XZbVldfmPnKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Constants\n",
        "Let's see some available constants. You can find the full list at https://docs.scipy.org/doc/scipy/reference/constants.html."
      ],
      "metadata": {
        "id": "R1vKrOhC-Buw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.constants as c\n",
        "\n",
        "print('Mathematical constants')\n",
        "print('PI:', c.pi)\n",
        "print('e:', c.e)\n",
        "print()\n",
        "print('Physical constants')\n",
        "print('Planck:', c.h)\n",
        "print('Newton:', c.g)\n",
        "print('Avogadro:', c.Avogadro)\n",
        "print('Speed of light:', c.speed_of_light)\n",
        "print('Elementary charge:', c.elementary_charge)\n",
        "print('Electron mass:', c.elementary_charge)\n",
        "print()\n",
        "print('Conversion')\n",
        "print('Degrees in a radian:', c.degree)\n",
        "print('Centigrade degrees in Farenheit:', c.degree_Fahrenheit)\n",
        "print('Pascals in Atmosphere:', c.atm)\n",
        "print('Cms per inch:', c.inch)\n",
        "print('Square meters in acre:', c.acre)\n"
      ],
      "metadata": {
        "id": "Ltq0HqsH-Kfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##K-Means\n",
        "The k-means algorithm takes as input the number of clusters to generate, k, and a set of observation vectors to cluster. It returns a set of centroids, one for each of the k clusters. An observation vector is classified with the cluster number or centroid index of the centroid closest to it."
      ],
      "metadata": {
        "id": "xh467kvzBflC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Bidimensional guess example\n",
        "Let's imagine a set of 100 points near the segment limited by point(-4, -4) and (4, 4).  "
      ],
      "metadata": {
        "id": "dEwFLKyyRKtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.cluster.vq import vq, kmeans, kmeans2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rng = np.random.default_rng()\n",
        "data = rng.multivariate_normal([1, 1], [[0, 1], [1, 1]], size = 100)\n",
        "plt.scatter(data[:, 0], data[:, 1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NIweUnygRJ28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's find two centroids."
      ],
      "metadata": {
        "id": "PvN9NuMLluxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codebook, d = kmeans(data, 2)\n",
        "codebook2, d2 = kmeans2(data, 2)\n",
        "plt.scatter(data[:, 0], data[:, 1])\n",
        "plt.scatter(codebook[:, 0], codebook[:, 1], c = 'red')\n",
        "plt.scatter(codebook2[:, 0], codebook2[:, 1], c = 'yellow')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VQp1fcbGltzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's find 4 centroids."
      ],
      "metadata": {
        "id": "yebS43ttmctR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codebook, d = kmeans(data, 4)\n",
        "codebook2, d2 = kmeans2(data, 4)\n",
        "plt.scatter(data[:, 0], data[:, 1])\n",
        "plt.scatter(codebook[:, 0], codebook[:, 1], c = 'red')\n",
        "plt.scatter(codebook2[:, 0], codebook2[:, 1], c = 'yellow')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3XgN6K0RmcVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's find 8 centroids."
      ],
      "metadata": {
        "id": "ZsIkzrktm3F0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codebook, d = kmeans(data, 8)\n",
        "codebook2, d2 = kmeans2(data, 8)\n",
        "plt.scatter(data[:, 0], data[:, 1])\n",
        "plt.scatter(codebook[:, 0], codebook[:, 1], c = 'red')\n",
        "plt.scatter(codebook2[:, 0], codebook2[:, 1], c = 'yellow')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e1yjHFkKm2sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Letter identification\n",
        "Let's code an image that contains a letter as a 3X5 pixel matrix. From 0 to 3 it could look like this:\n",
        "```\n",
        "ZERO ONE  TWO  THREE\n",
        " x     x  xxx  xx\n",
        "x x   xx    x    x\n",
        "x x    x   x    x\n",
        "x x    x  x      x\n",
        " x     x  xxx  xx\n",
        "```\n",
        "Let's code each `x` as a 1 and each `blank` as a 0 and write the pixels in just one array of data:\n",
        "```\n",
        "zero  = [0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0]\n",
        "one   = [0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
        "two   = [1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1]\n",
        "three = [0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
        "```\n",
        "Now we could code a few observations and check what k-means returns. **Let's play!**\n"
      ],
      "metadata": {
        "id": "0U-gukrvVw9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.cluster.vq import vq\n",
        "\n",
        "zero  = [0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0]\n",
        "one   = [0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
        "two   = [1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1]\n",
        "three = [1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0]\n",
        "code_book = np.array([zero, one, two, three])\n",
        "data = np.array([[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1], #noisy zero\n",
        "                 [1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1], #noisy two\n",
        "                 [1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0], #perfect three\n",
        "                 [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0], #noisy one\n",
        "                 [0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0], #perfect zero\n",
        "                 [1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1]])#very noisy three\n",
        "vq(data, code_book)"
      ],
      "metadata": {
        "id": "gskbYODKPvBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's play\n",
        "Add code to include 4 and 5 in the model and test it."
      ],
      "metadata": {
        "id": "TLyJNLnWaOyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here"
      ],
      "metadata": {
        "id": "-f4dxChbaYEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scikit Learn\n",
        "This is a library which contains simple and efficient tools for predictive data analysis. It is built on NumPy, SciPy, and MatPloLlib.\n",
        "\n",
        "You can find further details at https://scikit-learn.org/stable/index.html."
      ],
      "metadata": {
        "id": "WeIajxfBIwAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision tree\n",
        "Let's try to solve the number identification problem with a _decision tree_. "
      ],
      "metadata": {
        "id": "Ihj5WycGWp1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install sklearn\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "zero  = [0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0]\n",
        "one   = [0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
        "two   = [1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1]\n",
        "three = [1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0]\n",
        "X = pd.DataFrame([zero, one, two, three])\n",
        "y = pd.DataFrame({'result': [0, 1, 2, 3]})\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X, y)\n",
        "predictions = model.predict([[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1], #noisy zero\n",
        "                             [1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1], #noisy two\n",
        "                             [1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0], #perfect three\n",
        "                             [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0], #noisy one\n",
        "                             [0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0], #perfect zero\n",
        "                             [1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1]])#very noisy three\n",
        "predictions\n"
      ],
      "metadata": {
        "id": "61eKG-q9YYND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sklearn provides a way to show graphically how our classifier decides."
      ],
      "metadata": {
        "id": "e7BZON5kd-Zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "\n",
        "tree.export_graphviz(model,\n",
        "                     out_file = 'decision.dot',\n",
        "                     feature_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14'],\n",
        "                     class_names = ['0', '1', '2', '3'],\n",
        "                     label = 'all')"
      ],
      "metadata": {
        "id": "fmgLhYgUe8N6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's play\n",
        "Add code to include 4, 5, ... 9 in the models, test them and generate a visual decision tree."
      ],
      "metadata": {
        "id": "pfqO5M-rhnA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here"
      ],
      "metadata": {
        "id": "O4oLerNEhyYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nearest neighbour\n",
        "The principle behind **nearest neighbor** methods is to find a predefined number of training samples closest in distance to the new point, and predict the label from these. The **distance** can, in general, be any metric measure: standard Euclidean distance is the most common choice.\n",
        "\n",
        "Let's try to solve the number identification problem with this algorithm."
      ],
      "metadata": {
        "id": "uLoZlr0hh394"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install sklearn\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "\n",
        "zero  = [0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0]\n",
        "one   = [0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
        "two   = [1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1]\n",
        "three = [1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0]\n",
        "X = pd.DataFrame([zero, one, two, three])\n",
        "y = pd.DataFrame({'result': [0, 1, 2, 3]})\n",
        "\n",
        "model = NearestCentroid()\n",
        "model.fit(X, y)\n",
        "predictions = model.predict([[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1], #noisy zero\n",
        "                             [1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1], #noisy two\n",
        "                             [1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0], #perfect three\n",
        "                             [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0], #noisy one\n",
        "                             [0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0], #perfect zero\n",
        "                             [1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1]])#very noisy three\n",
        "predictions"
      ],
      "metadata": {
        "id": "S2iixIsah-My"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's play\n",
        "Add code to include 4, 5, ... 9 in the models and test them."
      ],
      "metadata": {
        "id": "RIdMjiiRjRO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here"
      ],
      "metadata": {
        "id": "wkDdklC3d9lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anaconda\n",
        "\n",
        "Check https://anaconda.org/anaconda/jupyter."
      ],
      "metadata": {
        "id": "6roGyL5qJuN3"
      }
    }
  ]
}