{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reading Files\n",
        "\n",
        "Any File can be accesed an read. A Python file object is created when a file is opened with the `open()` function. You can associate this file object with a variable when you open a file using the `with` and `as` keywords."
      ],
      "metadata": {
        "id": "1--YIakv4Iq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('sample_data/README.md') as file_object:\n",
        "  print(file_object)"
      ],
      "metadata": {
        "id": "w1CSYgKzGkDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using method ``readlines()`` is an easy way to access a file content line by line."
      ],
      "metadata": {
        "id": "aSpS-IwFHs2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('sample_data/anscombe.json') as file_object:\n",
        "  lines = file_object.readlines()\n",
        "  for line in lines:\n",
        "    print(line)"
      ],
      "metadata": {
        "id": "pI-y6AZ5ICZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## JSON File\n",
        "JSON  stands for **J**ava**S**cript **O**bject **N**otation.\n",
        "\n",
        "It is a lightweight format for storing and transporting data. It is self-describing, easy to understand and often used to send data from a server to a web page.\n",
        "\n",
        "You can find further information in https://www.w3schools.com/js/js_json_intro.asp.\n",
        "\n",
        "In Python, JSON data is read through the ``json`` module. The method ``load`` will map the content into a *dictionary*. "
      ],
      "metadata": {
        "id": "R_ogbEIF4QfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "  \n",
        "# Opening JSON file and read data\n",
        "file = open('sample_data/anscombe.json')\n",
        "data = json.load(file)\n",
        "\n",
        "# Iterating through the json\n",
        "for i in data:\n",
        "  print(i)\n",
        "\n",
        "for i in data[0]:\n",
        "  print(i, data[0][i])\n",
        "\n",
        "# Closing file\n",
        "file.close()"
      ],
      "metadata": {
        "id": "iFhnSq3qxIBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we have some JSON data contained in a string variable, we will use the method ``loads`` instead."
      ],
      "metadata": {
        "id": "C9OgrB_90XMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "  \n",
        "json_string = \"{\\\"who\\\": \\\"me\\\", \\\"when\\\": \\\"now\\\"}\"\n",
        "data = json.loads(json_string)\n",
        "  \n",
        "# Iterating through the json\n",
        "for i in data.keys():\n",
        "  print(i, \":\", data[i])"
      ],
      "metadata": {
        "id": "YK33iV_30kZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CSV File\n",
        "CSV stands for **C**omma **S**eparated **V**alues.\n",
        "\n",
        "A CSV file is a text file that has a specific format which allows data to be saved in a table structured format.\n",
        "\n",
        "In Python, CSV data is read through the ``csv`` module. The method ``reader`` will map the content of each line into an list."
      ],
      "metadata": {
        "id": "GuFQtRWC4Uvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('sample_data/california_housing_test.csv') as file:\n",
        "  csv_reader = csv.reader(file, delimiter = ',')\n",
        "  lines = 0\n",
        "  for row in csv_reader:\n",
        "    if lines == 0:\n",
        "      print(\"Column names are:\", \", \".join(row))\n",
        "    else:\n",
        "      print(row)\n",
        "    lines += 1\n",
        "    if lines >= 10:\n",
        "      break\n",
        "print(f'Processed {lines} lines.')"
      ],
      "metadata": {
        "id": "cKTL-B0j4ZHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A more handy way to read a CSV file is to use the ``DictReader`` method which converts each data row into a *dictionary*."
      ],
      "metadata": {
        "id": "N2c3PRW25N17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('sample_data/california_housing_test.csv') as file:\n",
        "  csv_reader = csv.DictReader(file, delimiter = ',')\n",
        "  lines = 0\n",
        "  for row in csv_reader:\n",
        "    print(row[\"latitude\"], row[\"longitude\"])\n",
        "    lines += 1\n",
        "    if lines >= 10:\n",
        "      break\n",
        "print(f'Processed {lines} lines with data.')"
      ],
      "metadata": {
        "id": "OmnGh49k5uk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas\n",
        "**Pandas** is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the **Python** programming language. Everything about pandas can be found at https://pandas.pydata.org/.\n",
        "\n",
        "It supports row and column metadata so any operation ment for tables can be acomplished with Pandas. There is a connector almost from any data source to Pandas, so it is suitable for data cleansing, combining and filtering.\n"
      ],
      "metadata": {
        "id": "b14wSbxv4aZr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Series and Dataframes\n",
        "\n",
        "The basic Pandas objects to work with data are ``Series`` and ``Dataframes``.\n",
        "\n",
        "You can think of a ``Series`` as the column of a table."
      ],
      "metadata": {
        "id": "2WzvonXcmZyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = [1, 7, 2]\n",
        "s = pd.Series(data)\n",
        "s"
      ],
      "metadata": {
        "id": "0g012D8ukIrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, by default, values are labeled with its index number. But if we use a ``dictionary`` as the `Series` data, labels are set.\n",
        "\n"
      ],
      "metadata": {
        "id": "DpKGjP2XkmYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "steps = {\"day1\": 42045, \"day2\": 38045, \"day3\": 43390}\n",
        "s = pd.Series(steps)\n",
        "s"
      ],
      "metadata": {
        "id": "wA96o_PgklGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data sets in Pandas are usually multi-dimensional tables, called `Dataframes`. A Dataframe may be built by joining series.\n",
        "\n",
        "More info at https://pandas.pydata.org/docs/reference/frame.html."
      ],
      "metadata": {
        "id": "kWVPu2MFmgH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "steps = {\"day1\": 42045, \"day2\": 38045, \"day3\": 43390}\n",
        "s = pd.Series(steps)\n",
        "calories_intake = {\"day1\": 2051, \"day2\": 1945, \"day3\": 3390}\n",
        "c_in = pd.Series(calories_intake)\n",
        "calories_gym = {\"day1\": 0, \"day2\": 395, \"day3\": 698}\n",
        "c_gym = pd.Series(calories_gym)\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['steps'] = s\n",
        "df['cals_in'] = c_in\n",
        "df['cals_gym'] = c_gym\n",
        "df"
      ],
      "metadata": {
        "id": "HDN5bZWVqMop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data from lists\n",
        "Let's create a dataframe with a couple of lists in a disctionary."
      ],
      "metadata": {
        "id": "uTBJPtmp43XA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "  \"longitude\": [30.23423, 25.98798, 13.00974],\n",
        "  \"latitude\": [15.09884, 12.02374, 16.98732]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "metadata": {
        "id": "Y6AqOyd444Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data from CSV\n",
        "Let's read a CSV file and manipulate its data with pandas."
      ],
      "metadata": {
        "id": "VIzOSbpQllyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('sample_data/california_housing_test.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "X48gK4fI6KNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yo can check in https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html a complete reference of what you can do with a dataframe. \n"
      ],
      "metadata": {
        "id": "dC3ev-qbWHCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Operations\n",
        "\n",
        "Let's check what does the dataframe contain."
      ],
      "metadata": {
        "id": "QZPSmf69iXQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "print()\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "s2VZMt3aTXfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's **sort** the `dataframe`."
      ],
      "metadata": {
        "id": "odoFHx8uTMVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sorted = df.sort_values(['housing_median_age', 'latitude'])\n",
        "df_sorted"
      ],
      "metadata": {
        "id": "G2x15uBWWCDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's **rearrange** data and keep just a few columns."
      ],
      "metadata": {
        "id": "-8r90W_Tb9vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_reshaped = df_sorted.reindex(columns = ['housing_median_age', 'latitude'])\n",
        "df_reshaped"
      ],
      "metadata": {
        "id": "-Rn72EpMb6uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or even easier."
      ],
      "metadata": {
        "id": "W5tnzTmtaR3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_reshaped_again = df_sorted[['housing_median_age', 'latitude', 'longitude']]\n",
        "df_reshaped_again"
      ],
      "metadata": {
        "id": "sgg1Sm3-bN0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also combine two Dataframes in different ways.\n",
        "\n",
        "We may **concatenate** two or more dataframes, like in an SQL union."
      ],
      "metadata": {
        "id": "YalLFb8px-dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data1 = {\n",
        "  \"id\": [1, 2, 3],\n",
        "  \"name\": [\"John\", \"Mike\", \"Troy\"]\n",
        "}\n",
        "data2 = {\n",
        "  \"id\": [10, 11, 3],\n",
        "  \"name\": [\"Steve\", \"Ray\", \"Troy\"]\n",
        "}\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "print(df1)\n",
        "print(df2)\n",
        "\n",
        "# check what happen with and without ignore_index\n",
        "pd.concat([df1, df2], ignore_index = True)"
      ],
      "metadata": {
        "id": "-syCJaZ565rL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To join data with different column names"
      ],
      "metadata": {
        "id": "3Vg0gCgW92oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data1 = {\n",
        "  \"id\": [1, 2, 3],\n",
        "  \"first name\": [\"John\", \"Mike\", \"Troy\"]\n",
        "}\n",
        "data2 = {\n",
        "  \"id\": [10, 11, 12],\n",
        "  \"last name\": [\"Rambo\", \"Tyson\", \"Aikman\"]\n",
        "}\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "print(df1)\n",
        "print(df2)\n",
        "\n",
        "# check what happen with and without ignore_index\n",
        "pd.concat([df1, df2], axis = 0, ignore_index = True)"
      ],
      "metadata": {
        "id": "MyS2Oq95915H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also **merge** dataframes like in an SQL join."
      ],
      "metadata": {
        "id": "39tw6wfB4CwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data1 = {\n",
        "  \"id\": [1, 2, 3],\n",
        "  \"first name\": [\"John\", \"Mike\", \"Troy\"]\n",
        "}\n",
        "data2 = {\n",
        "  \"id\": [1, 2, 4],\n",
        "  \"last name\": [\"Rambo\", \"Tyson\", \"Aikman\"]\n",
        "}\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# how can take 'inner', 'left', 'right' or 'outer'\n",
        "pd.merge(df1, df2, on = 'id', how = 'outer')"
      ],
      "metadata": {
        "id": "WQA313TVx3sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformations\n",
        "Let's see how to do some easy transformations with pandas Dataframes.  "
      ],
      "metadata": {
        "id": "NAJ7JZ8SFrAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning\n",
        "We can remove empty values"
      ],
      "metadata": {
        "id": "_jor01q3FvIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "  \"id\": [1, 2, 3],\n",
        "  \"first name\": [\"John\", None, \"Troy\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "df.dropna()"
      ],
      "metadata": {
        "id": "bnzngxy8G9Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can remove duplicated rows"
      ],
      "metadata": {
        "id": "n8Wb0TfhG5UR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "  \"id\": [1, 2, 2],\n",
        "  \"first name\": [\"John\", \"Mike\", \"Mike\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "df.drop_duplicates()"
      ],
      "metadata": {
        "id": "pPHFgSh2G-Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or we can remove data we don't need"
      ],
      "metadata": {
        "id": "EQOGtw4pGxV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "  \"id\": [1, 2, 3],\n",
        "  \"first name\": [\"John\", \"Mike\", \"Troy\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "for x in df.index:\n",
        "  if df.loc[x, \"id\"] == 1:\n",
        "    df.drop(x, inplace = True)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "mo-xudkWG9gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Replacing"
      ],
      "metadata": {
        "id": "ODnM1QyaIA7S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can replace empty values"
      ],
      "metadata": {
        "id": "GIU1V-SlJavn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "  \"id\": [1, 2, 3, None],\n",
        "  \"first name\": [\"John\", None, \"Troy\", \"Steve\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "df.fillna('NOTHING HERE')"
      ],
      "metadata": {
        "id": "-hK9d8HQh7KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or better"
      ],
      "metadata": {
        "id": "-m9KDvTSiTEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "  \"id\": [1, 2, 3, None],\n",
        "  \"first name\": [\"John\", None, \"Troy\", \"Steve\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "# see what happens with inplace = True\n",
        "df[\"id\"].fillna(0, inplace = True)\n",
        "df[\"first name\"].fillna(\"Someone\", inplace = True)\n",
        "df"
      ],
      "metadata": {
        "id": "hoKFH1O5iWh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can transform data."
      ],
      "metadata": {
        "id": "tHY0TYE1JaXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "  \"id\": [1, 2, 3, 4],\n",
        "  \"first name\": [\"John\", \"Mike\", \"Troy\", \"Steve\"],\n",
        "  \"birth_date\": [\"2020-01-10\", \"2017-06-20\", \"2010-11-13\", \"2020-11-30\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df.info())\n",
        "print()\n",
        "df"
      ],
      "metadata": {
        "id": "EpBhOdhZjn9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['birth_date'] = pd.to_datetime(df['birth_date'])\n",
        "print(df.info())\n",
        "print()\n",
        "df"
      ],
      "metadata": {
        "id": "qcPPEXSlHz9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or we can add columns based on existing ones"
      ],
      "metadata": {
        "id": "BWkWprvmJsMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "  \"id\": [1, 2, 3, 4],\n",
        "  \"first name\": [\"John\", \"Mike\", \"Troy\", \"Steve\"],\n",
        "  \"birth_date\": [\"2020-01-10\", \"2017-06-20\", \"2010-11-13\", \"2020-11-30\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "print()\n",
        "\n",
        "df['birth_date_day'] = pd.to_datetime(df['birth_date']).dt.day\n",
        "df['birth_date_month'] = pd.to_datetime(df['birth_date']).dt.month\n",
        "df['birth_date_year'] = pd.to_datetime(df['birth_date']).dt.year\n",
        "df['zero'] = 0\n",
        "df"
      ],
      "metadata": {
        "id": "WWFpGI23kpYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extracting\n",
        "As you have already seen, you can extract just a few columns in a dataframe by passing the list of the fields you need."
      ],
      "metadata": {
        "id": "4_AaxJMzF37q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "  \"id\": [1, 2, 3, 4],\n",
        "  \"first name\": [\"John\", \"Mike\", \"Troy\", \"Steve\"],\n",
        "  \"birth_date\": [\"2020-01-10\", \"2017-06-20\", \"2010-11-13\", \"2020-11-30\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "df[['id', 'birth_date']]"
      ],
      "metadata": {
        "id": "5E54l2MiiQKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With ``head()`` you can select just the first N rows"
      ],
      "metadata": {
        "id": "CF-uUKLji--p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "  \"id\": [1, 2, 3, 4],\n",
        "  \"first name\": [\"John\", \"Mike\", \"Troy\", \"Steve\"],\n",
        "  \"birth_date\": [\"2020-01-10\", \"2017-06-20\", \"2010-11-13\", \"2020-11-30\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "6NSGcSh7i6mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or you can pass a condition to obtain just a set of rows"
      ],
      "metadata": {
        "id": "iuucHcIfjfvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "  \"id\": [1, 2, 3, 4],\n",
        "  \"first name\": [\"John\", \"Mike\", \"Troy\", \"Steve\"],\n",
        "  \"birth_date\": [\"2020-01-10\", \"2017-06-20\", \"2010-11-13\", \"2020-11-30\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "df[df[\"id\"] >= 3]"
      ],
      "metadata": {
        "id": "bWZdemW0jfIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Grouping\n",
        "Data can be grouped and "
      ],
      "metadata": {
        "id": "tohF27VakLMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "  \"score\": [14, 21, 38, 45, 34, 74, 2, 44, 23, 9, 81, 43],\n",
        "  \"player\": [\"John\", \"Mike\", \"Troy\", \"Steve\", \"John\", \"Mike\", \"Troy\", \"Steve\", \"John\", \"Mike\", \"Troy\", \"Steve\"],\n",
        "  \"date\": [\"2020-01-10\", \"2020-01-10\", \"2020-01-10\", \"2020-01-10\", \n",
        "                 \"2020-01-11\", \"2020-01-11\", \"2020-01-11\", \"2020-01-11\", \n",
        "                 \"2020-01-12\", \"2020-01-12\", \"2020-01-12\", \"2020-01-12\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "print()\n",
        "print(df.groupby(\"player\")[\"date\"].count())\n",
        "print()\n",
        "print(df.groupby(\"player\")[\"score\"].sum())"
      ],
      "metadata": {
        "id": "GXnnpCHo1Ex4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All together using ``numpy`` (see next section)."
      ],
      "metadata": {
        "id": "pvNBxUl87EdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "df.groupby(\"player\").agg({\"date\": np.size, \"score\": np.sum })"
      ],
      "metadata": {
        "id": "pZedmpfr7FdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pivoting\n",
        "A pivot table is a statistics tool that summarizes and reorganizes selected columns and rows of data in a table to obtain a desired report. The tool does not actually change the table itself, it simply _pivots_ or turns the data to view it from a **different perspective**.\n",
        "\n",
        "When creating a pivot table, there are three main components:\n",
        "\n",
        "- **Columns**: When a field is chosen for the column area, only the unique values of the field are listed across the top.\n",
        "- **Rows**: When a field is chosen for the row area, it populates as the first column. Similar to the columns, all row labels are the unique values and duplicates are removed.\n",
        "- **Values**: Each value is kept in a pivot table cell and display the summarized information. The most common values are sum, average, minimum and maximum.\n"
      ],
      "metadata": {
        "id": "9cvjgiAMJbvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# a list of order lines with its user\n",
        "df = pd.DataFrame(\n",
        "  {\n",
        "    'order_id': ['0001', '0001', '0002', '0002', '0002', '0003', '0004', '0004'],\n",
        "    'user_name': ['john', 'john', 'mike', 'mike', 'mike', 'tony', 'mike', 'emma'],\n",
        "    'product_id': [1, 2, 2, 4, 6, 2, 1, 6],\n",
        "    'amount': [1, 1, 2, 4, 1, 1, 3, 2]\n",
        "   }\n",
        ")\n",
        "print('Original')\n",
        "print(df)\n",
        "print()\n",
        "print('Pivots')\n",
        "\n",
        "# different pivots\n",
        "df.pivot(columns = 'user_name')"
      ],
      "metadata": {
        "id": "A2E-bKyWj3GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.pivot(columns = 'user_name', values = 'amount')"
      ],
      "metadata": {
        "id": "YyM4gliIImPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.pivot(columns = 'user_name', values = 'amount', index = 'product_id')"
      ],
      "metadata": {
        "id": "3bAL1htOInHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation\n",
        "**Correlaton** refers to the interdependence of quantities expressed as a float number between ``-1.0`` and ``1.0`` depending whether the correlaton is perfect and negative or positive. Correlation can be calculated in two ways:\n",
        "- between columns of a dataframe\n",
        "- between two dataframes"
      ],
      "metadata": {
        "id": "WU3ldaozJGLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(\n",
        "  {\n",
        "    'age': [11, 12, 12, 4, 16, 22, 31, 16, 33, 18, 20, 20, 23, 4, 13],\n",
        "    'occurrences': [1, 1, 2, 4, 1, 1, 3, 2, 4, 2, 3, 0, 1, 3, 4]\n",
        "   }\n",
        ")\n",
        "print(df.corr(min_periods = 1, method = 'pearson'))\n",
        "print()\n",
        "print(df.corr(min_periods = 5, method = 'kendall'))\n",
        "print()\n",
        "df.corr(min_periods = 10, method = 'spearman')\n"
      ],
      "metadata": {
        "id": "CmJRCah0-8p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.DataFrame(\n",
        "  {\n",
        "    'age': [11, 12, 12, 4, 16, 22, 31, 16, 33, 18, 20, 20, 23, 4, 13],\n",
        "    'occurrences': [1, 1, 2, 4, 1, 1, 3, 2, 4, 2, 3, 0, 1, 3, 4]\n",
        "   }\n",
        ")\n",
        "df2 = pd.DataFrame(\n",
        "  {\n",
        "    'age': [11, 12, 12, 14, 16, 22, 31, 16, 23, 18, 20, 20, 23, 14, 13],\n",
        "    'occurrences': [3, 1, 1, 2, 4, 1, 1, 3, 2, 4, 2, 3, 0, 1, 3]\n",
        "   }\n",
        ")\n",
        "df1.corrwith(df2, axis = 0)"
      ],
      "metadata": {
        "id": "Iihay_A_Bz1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rolling\n",
        "A rolling window model is used to check the stability of a model, commonly over a time series. We usually stablish the size of a **time window** where we calculate the mean and compare against the value.\n",
        "\n",
        "_(*) In a Python dataframe, we can calculate rolling without a time index._\n",
        "\n",
        "_(**) And we can apply different calculations on the window values._"
      ],
      "metadata": {
        "id": "TQrnZ8rBJrg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(\n",
        "  {\n",
        "    'occurrences': [11, 12, 12,  4, 16, 22, 31, 16, 33, 18,\n",
        "                    20, 23,  4, 13, 12, 51, 23, 27,  9, 15, \n",
        "                    34,  8, 23, 17,  9, 30, 20, 12, 21, 18, 9]\n",
        "  },\n",
        "  index = [\"2023-01-01\", \"2023-01-02\", \"2023-01-03\", \"2023-01-04\", \"2023-01-05\", \"2023-01-06\", \n",
        "           \"2023-01-07\", \"2023-01-08\", \"2023-01-09\", \"2023-01-10\", \"2023-01-11\", \"2023-01-12\", \n",
        "           \"2023-01-13\", \"2023-01-14\", \"2023-01-15\", \"2023-01-16\", \"2023-01-17\", \"2023-01-18\", \n",
        "           \"2023-01-19\", \"2023-01-20\", \"2023-01-21\", \"2023-01-22\", \"2023-01-23\", \"2023-01-24\", \n",
        "           \"2023-01-25\", \"2023-01-26\", \"2023-01-27\", \"2023-01-28\", \"2023-01-29\", \"2023-01-30\", \"2023-01-31\"]\n",
        ")\n",
        "df['rolling_occ'] = df['occurrences'].rolling(7, min_periods = 1, center = True).mean()\n",
        "df"
      ],
      "metadata": {
        "id": "8S-z3B2mWS1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Plotting\n",
        "Although there are better alternatives for drawing information in graphs, we can use the ``pandas`` library to plot data.\n",
        "\n",
        "Visit https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html for further info."
      ],
      "metadata": {
        "id": "3eIhK6XOmCr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(\n",
        "  {\n",
        "    'occurrences': [11, 12, 12,  4, 16, 22, 31, 16, 33, 18,\n",
        "                    20, 23,  4, 13, 12, 51, 23, 27,  9, 15, \n",
        "                    34,  8, 23, 17,  9, 30, 20, 12, 21, 18, 9]\n",
        "  },\n",
        "  index = [\"2023-01-01\", \"2023-01-02\", \"2023-01-03\", \"2023-01-04\", \"2023-01-05\", \"2023-01-06\", \n",
        "           \"2023-01-07\", \"2023-01-08\", \"2023-01-09\", \"2023-01-10\", \"2023-01-11\", \"2023-01-12\", \n",
        "           \"2023-01-13\", \"2023-01-14\", \"2023-01-15\", \"2023-01-16\", \"2023-01-17\", \"2023-01-18\", \n",
        "           \"2023-01-19\", \"2023-01-20\", \"2023-01-21\", \"2023-01-22\", \"2023-01-23\", \"2023-01-24\", \n",
        "           \"2023-01-25\", \"2023-01-26\", \"2023-01-27\", \"2023-01-28\", \"2023-01-29\", \"2023-01-30\", \"2023-01-31\"]\n",
        ")\n",
        "df.plot.area()\n",
        "df.plot.line()\n",
        "df.plot.bar()"
      ],
      "metadata": {
        "id": "iZeiChXNrYMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What's next?\n",
        "Let's learn how to use some libraries:\n",
        "\n",
        "- NumPy\n",
        "- SciPy\n",
        "- MatPlotLib\n",
        "- Seaborn\n",
        "- StatsModel\n",
        "- ScikitLearn"
      ],
      "metadata": {
        "id": "5jCC1oIgebi7"
      }
    }
  ]
}